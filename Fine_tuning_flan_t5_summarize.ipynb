{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abonia1/LLM-finetuning/blob/main/Fine_tuning_flan_t5_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14410483",
      "metadata": {
        "id": "14410483"
      },
      "source": [
        "# Hugging Face - Summarization \n",
        "\n",
        "This source code builds the fine-tuned model of [google/flan-t5-small](https://huggingface.co/google/flan-t5-small) for summarization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab3bf825",
      "metadata": {
        "id": "ab3bf825"
      },
      "source": [
        "Install packages depending on T5 tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12a86426",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12a86426",
        "outputId": "4480fa93-8015-4961-a2c9-cac5335e178e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b66d94",
      "metadata": {
        "id": "d4b66d94"
      },
      "source": [
        "Install packages depending on rouge evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aee740d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aee740d4",
        "outputId": "b0c2b93c-51b7-4a01-df3e-211ab34a61b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install absl-py rouge_score nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "631a81ff",
      "metadata": {
        "id": "631a81ff"
      },
      "source": [
        "Install other dependent packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "95588a34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95588a34",
        "outputId": "6cbd4020-68f5-4bae-ead3-60800fb3d32a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.28.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsFrRNKXgHcg",
        "outputId": "5f4eff1e-8d11-4980-814b-4f6f648fc34d"
      },
      "id": "YsFrRNKXgHcg",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UupkysLLT7BF",
        "outputId": "6a4ff24b-ebf3-4b10-8fe1-a7b47b7811dd"
      },
      "id": "UupkysLLT7BF",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04ef40e",
      "metadata": {
        "id": "c04ef40e"
      },
      "source": [
        "## Check device\n",
        "\n",
        "Check whether GPU is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f5bc098b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5bc098b",
        "outputId": "fea7f3b1-e05c-41d0-93e8-141253da19a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is enabled.\n",
            "device count: 1, current device: 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is enabled.\")\n",
        "    print(\"device count: {}, current device: {}\".format(torch.cuda.device_count(), torch.cuda.current_device()))\n",
        "else:\n",
        "    print(\"GPU is not enabled.\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5163ab77",
      "metadata": {
        "id": "5163ab77"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "In this example, we use [XL-Sum english dataset](https://huggingface.co/datasets/csebuetnlp/xlsum/viewer/english) in Hugging Face, which is the annotated article-summary pairs generated by BBC.<br>\n",
        "This dataset has around 7000 samples for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "20a1866b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "97f6a925f3ac4f538d3335162c98d4bc",
            "864e0a05db1340f5b7dabeca9e048ba8",
            "a8c78d4dc5c54ed8b1d142e59a39d461",
            "882f45a3556e44fba9e76b6472f4905d",
            "5effb11eac674eaca26d4f82d85e8dfc",
            "0d5659b56a7f450e880944fe2dd0daa0",
            "a309d0de0f17402bb5621bc1ec16a4b4",
            "7aef40e8d19a4903abc86c66577aaaae",
            "f28d9138eb004227bedc0556007f313b",
            "41968fbc0f424c5f93de98e7c7ec6ed7",
            "006db2251be24fe7b99a7ec4932da692"
          ]
        },
        "id": "20a1866b",
        "outputId": "1cf3a661-6e45-468b-c81f-01bac0e6daa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset xlsum (/root/.cache/huggingface/datasets/csebuetnlp___xlsum/english/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f6a925f3ac4f538d3335162c98d4bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
              "        num_rows: 306522\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
              "        num_rows: 11535\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
              "        num_rows: 11535\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"csebuetnlp/xlsum\", name=\"english\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c8da181d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8da181d",
        "outputId": "b7cb1650-45a3-4c8b-83b3-4b3820159075"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'uk-wales-56321577',\n",
              " 'url': 'https://www.bbc.com/news/uk-wales-56321577',\n",
              " 'title': 'Weather alert issued for gale force winds in Wales',\n",
              " 'summary': 'Winds could reach gale force in Wales with stormy weather set to hit the whole of the country this week.',\n",
              " 'text': 'The Met Office has issued a yellow weather warning for wind covering Wales and England, starting from 21:00 GMT on Wednesday evening. Travel and power are both likely to be disrupted, with the warning to remain in place until 15:00 on Thursday. Gusts of 55mph (88kmh) are likely and could hit up to 70mph on coasts and hills, with heavy and blustery showers.'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "453c922d",
      "metadata": {
        "id": "453c922d"
      },
      "source": [
        "To generate inputs for fine-tuning, now I tokenize each text and convert into token ids.\n",
        "\n",
        "First, load tokenizer in pre-trained ```google/flan-t5-small``` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c42045d0",
      "metadata": {
        "id": "c42045d0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "#t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8231f7",
      "metadata": {
        "id": "bd8231f7"
      },
      "source": [
        "For fine-tuning, apply tokenization for dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "714d1453",
      "metadata": {
        "id": "714d1453"
      },
      "outputs": [],
      "source": [
        "def tokenize_sample_data(data):\n",
        "    # Max token size is 14536 and 215 for inputs and labels, respectively.\n",
        "    # Here I restrict these token size.\n",
        "    input_feature = t5_tokenizer(data[\"text\"], truncation=True, max_length=1024)\n",
        "    label = t5_tokenizer(data[\"summary\"], truncation=True, max_length=128)\n",
        "    return {\n",
        "        \"input_ids\": input_feature[\"input_ids\"],\n",
        "        \"attention_mask\": input_feature[\"attention_mask\"],\n",
        "        \"labels\": label[\"input_ids\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "26b32615",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323,
          "referenced_widgets": [
            "5b8348abac7a4f0ca72a2fd9d95cfae0",
            "e27f5ec664944be184f9d8f27b6b97b7",
            "9a2e6b142cbf41bbb4e3c23851087bf3",
            "5a237c27ae2e4a4f863e39c06a956ddd",
            "601d10293ac3472c8f244a11ca9c9204",
            "9853745fd4154c6590e257ee175fe030",
            "8f47cf72871344cfbe2eceb7a55353f6",
            "ff1aac87f32f4cd182a77e1c43a80ab2",
            "732eb793dce0479ca2c98f1a39161c99",
            "c0ab811164014053b2d135909b931801",
            "a37de51cf1504c5d8593af7ab3a578ab"
          ]
        },
        "id": "26b32615",
        "outputId": "071fafe0-0e51-4766-ccfa-5c7be3e25353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csebuetnlp___xlsum/english/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce/cache-6c8cb73b8cdba8d4.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11535 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b8348abac7a4f0ca72a2fd9d95cfae0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csebuetnlp___xlsum/english/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce/cache-f80b01d2cb4991b0.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 306522\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 11535\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 11535\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenized_ds = ds.map(\n",
        "    tokenize_sample_data,\n",
        "    remove_columns=[\"id\", \"url\", \"title\", \"summary\", \"text\"],\n",
        "    batched=True,\n",
        "    batch_size=128)\n",
        "tokenized_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692dd056",
      "metadata": {
        "id": "692dd056"
      },
      "source": [
        "## Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf379a1",
      "metadata": {
        "id": "4bf379a1"
      },
      "source": [
        "In this example, we use flan-t5 model.<br>\n",
        "There exist several sizes of flan-t5 and I'll use small one (```google/flan-t5-small```) to fit to memory in my machine. The name is \"small\", but it's still so large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "39cab1c7",
      "metadata": {
        "id": "39cab1c7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelForSeq2SeqLM\n",
        "\n",
        "# see https://huggingface.co/docs/transformers/main_classes/configuration\n",
        "flant5_config = AutoConfig.from_pretrained(\n",
        "    \"google/flan-t5-small\",\n",
        "    max_length=128,\n",
        "    length_penalty=0.6,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=15,\n",
        ")\n",
        "model = (AutoModelForSeq2SeqLM\n",
        "         .from_pretrained(\"google/flan-t5-small\", config=flant5_config)\n",
        "         .to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30cb5336",
      "metadata": {
        "id": "30cb5336"
      },
      "source": [
        "We prepare data collator, which works for preprocessing data.\n",
        "\n",
        "For the sequence-to-sequence (seq2seq) task, we need to not only stack the inputs for encoder, but also prepare for the decoder side. In seq2seq setup, a common technique called \"teach forcing\" will then be applied in decoder.<br>\n",
        "These tasks are not needed to manually setup in Hugging Face, and ```DataCollatorForSeq2Seq``` will take care of all steps.\n",
        "\n",
        "In this collator, the padded token will also be filled with label id -100.<br>\n",
        "This token will then be ignored in the sebsequent loss computation and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bc213f22",
      "metadata": {
        "id": "bc213f22"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    t5_tokenizer,\n",
        "    model=model,\n",
        "    return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b9c9f14",
      "metadata": {
        "id": "6b9c9f14"
      },
      "source": [
        "We also prepare metrics function for evaluation in the training.<br>\n",
        "Measuring the quality of generated text is very difficult, and BLEU and ROUGE are often used.\n",
        "\n",
        "Briefly speaking, BLEU measures how many of n-grams in the generated (predicted) text are overlaped in the reference text. This score is used for evaluation, especially in the machine translation task.\n",
        "However, in summarization, we need all important words (which appears on the reference text) in the generated text. This is because we often use ROUGE in summarization tasks.\n",
        "The idea of ROUGE is similar to BLEU, but it also measures how many of n-grams in the reference text appears in the generated (predicted) text. (This is why the name of ROUGE includes \"RO\", which means \"Recall-Oriented\".)<br>\n",
        "There also exist variations, ROUGE-L and ROUGE-Lsum, which also measures the longest common substrings (LCS).\n",
        "\n",
        "In Hugging Face, you don't need to manually implement these logics and can use built-in objects for scoring these matrics.<br>\n",
        "In this example, I have configured flan-t5 tokenization as custom tokenization in computation (which is based on SentencePiece Unigram segmentation), because the white space tokenization is used as default in ROUGE evaluation.\n",
        "\n",
        "> Note : You can also specify multilingual stemmer.\n",
        "\n",
        "> Note : As I have mentioned above, the padded token id becomes -100 by data collator and I then also convert it into padded token id before processing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ_xUUYnexzj",
        "outputId": "97f63ee1-bd07-4f86-fcd3-0fb93df28372"
      },
      "id": "dJ_xUUYnexzj",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlZGCzE3fBw-",
        "outputId": "394c3a12-0336-410b-97da-c1105993900c"
      },
      "id": "hlZGCzE3fBw-",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f5dd0da9",
      "metadata": {
        "id": "f5dd0da9"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "def tokenize_sentence(arg):\n",
        "    encoded_arg = t5_tokenizer(arg)\n",
        "    return t5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
        "\n",
        "def metrics_func(eval_arg):\n",
        "    preds, labels = eval_arg\n",
        "    # Replace -100\n",
        "    labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
        "    # Convert id tokens to text\n",
        "    text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
        "    # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
        "    text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
        "    text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
        "    sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
        "    text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
        "    text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
        "    # compute ROUGE score with custom tokenization\n",
        "    return rouge_metric.compute(\n",
        "        predictions=text_preds,\n",
        "        references=text_labels,\n",
        "        tokenizer=tokenize_sentence\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dde59f4",
      "metadata": {
        "id": "7dde59f4"
      },
      "source": [
        "Before fine-tuning, now I check ROUGE score with plain flan-t5 model. Here I check scores for top 5 rows in test dataset.\n",
        "\n",
        "The score is very low, because this model is not trained for any downstream tasks. (It's just trained by unsupervised approach.)\n",
        "\n",
        "> Note : In order to avoid suboptimal text generation, here I have applied beam search for the text generation algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a5e99037",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5e99037",
        "outputId": "566655db-ea3b-4bbe-ce08-e0236df261a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.3624369577411001,\n",
              " 'rouge2': 0.12602818905339913,\n",
              " 'rougeL': 0.24435002241919287,\n",
              " 'rougeLsum': 0.24435002241919287}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "sample_dataloader = DataLoader(\n",
        "    tokenized_ds[\"test\"].with_format(\"torch\"),\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=5)\n",
        "for batch in sample_dataloader:\n",
        "    with torch.no_grad():\n",
        "        preds = model.generate(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            num_beams=15,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=1,\n",
        "            remove_invalid_values=True,\n",
        "            max_length=128,\n",
        "        )\n",
        "    labels = batch[\"labels\"]\n",
        "    break\n",
        "\n",
        "metrics_func([preds, labels])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f4bfded",
      "metadata": {
        "id": "9f4bfded"
      },
      "source": [
        "We prepare training arguments for fine-tuning.<br>\n",
        "In this example, we use HuggingFace transformer trainer class, with which you can run training without manually writing training loop.\n",
        "\n",
        "In usual training evaluation, training loss and accuracy will be computed and evaluated, by comparing the generated logits with labels. However, as we saw above, we want to evaluate ROUGE score using the predicted tokens.<br>\n",
        "To simplify these sequence-to-sequence specific steps, here I use built-in ```Seq2SeqTrainingArguments``` and ```Seq2SeqTrainer``` classes in HuggingFace, instead of usual ```TrainingArguments``` and ```Trainer```.<br>\n",
        "By setting ```predict_with_generate=True``` in this class, the predicted tokens generated by  ```model.generate()``` will be used in each evaluation.\n",
        "\n",
        "The checkpoint files (in each 500 steps) are saved in the folder named ```flan-t5-summarize-en```.\n",
        "\n",
        "> Note : Do not use FP16 precision in flan-t5 fine-tuning.\n",
        "\n",
        "> Note : In general, the saved checkpoints in the training will become so large.<br>\n",
        "> Set ```save_total_limit``` property (which limits the total amount of checkpoints by deleting the older ones) to save disk spaces, or expand disks in Azure VM. (See [here](https://learn.microsoft.com/en-us/azure/virtual-machines/linux/expand-disks) to expand disks in Azure.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nLIPUlffoOg",
        "outputId": "6b20949d-0243-4e5f-ce3a-965f94a3abb9"
      },
      "id": "6nLIPUlffoOg",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "78f28731",
      "metadata": {
        "id": "78f28731"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir = \"flant5-summarize-en\",\n",
        "    log_level = \"error\",\n",
        "    num_train_epochs = 10,\n",
        "    learning_rate = 5e-4,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    warmup_steps = 90,\n",
        "    optim = \"adafactor\",\n",
        "    weight_decay = 0.01,\n",
        "    per_device_train_batch_size = 2,\n",
        "    per_device_eval_batch_size = 1,\n",
        "    gradient_accumulation_steps = 16,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    eval_steps = 100,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length = 128,\n",
        "    save_steps = 500,\n",
        "    logging_steps = 10,\n",
        "    push_to_hub = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir = \"flant5-summarize-en\",\n",
        "    log_level = \"error\",\n",
        "    num_train_epochs = 5,   # Decreased number of epochs\n",
        "    learning_rate = 1e-4,   # Decreased learning rate\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    warmup_steps = 90,\n",
        "    optim = \"adafactor\",\n",
        "    weight_decay = 0.01,\n",
        "    per_device_train_batch_size = 8,   # Increased batch size\n",
        "    per_device_eval_batch_size = 4,   \n",
        "    gradient_accumulation_steps = 4,   # Decreased gradient accumulation steps\n",
        "    evaluation_strategy = \"steps\",\n",
        "    eval_steps = 200,   # Decreased evaluation frequency\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length = 256,   # Increased summary length\n",
        "    save_steps = 500,\n",
        "    logging_steps = 10,\n",
        "    push_to_hub = False\n",
        ")\"\"\"\n"
      ],
      "metadata": {
        "id": "LAJDHy6X93ct"
      },
      "id": "LAJDHy6X93ct",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3978f071",
      "metadata": {
        "id": "3978f071"
      },
      "source": [
        "Build trainer. (Put it all together.)\n",
        "\n",
        "Because the cost of evaluation computation (ROUGE scoring) is so high, I have then decreased the number of rows in validation set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"flant5-xlsum\",\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_first_step=True,\n",
        "    overwrite_output_dir=True,\n",
        "    max_steps=500,  # Terminate training after 500 steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "slI3NMqSIEl4"
      },
      "id": "slI3NMqSIEl4",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bca8a572",
      "metadata": {
        "id": "bca8a572"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = metrics_func,\n",
        "    train_dataset = tokenized_ds[\"train\"],\n",
        "    eval_dataset = tokenized_ds[\"validation\"].select(range(20)),\n",
        "    tokenizer = t5_tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8b530f",
      "metadata": {
        "id": "ce8b530f"
      },
      "source": [
        "Now let's run training.<br>\n",
        "As you will find, ROUGE scores are growing during training.\n",
        "\n",
        "> Note : As I have mentioned above, make sure that you have enough disk space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a66059ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a66059ec",
        "outputId": "682b839b-a76c-428f-fb27-a88ab3b62296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.0, 'learning_rate': 0.0003, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'learning_rate': 9.96e-05, 'epoch': 0.03}\n",
            "{'train_runtime': 452.2943, 'train_samples_per_second': 17.688, 'train_steps_per_second': 1.105, 'train_loss': 0.0, 'epoch': 0.03}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.0, metrics={'train_runtime': 452.2943, 'train_samples_per_second': 17.688, 'train_steps_per_second': 1.105, 'train_loss': 0.0, 'epoch': 0.03})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44578fb6",
      "metadata": {
        "id": "44578fb6"
      },
      "source": [
        "In order to use it later, you can save the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0710012a",
      "metadata": {
        "id": "0710012a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"./trained_for_summarization_en\", exist_ok=True)\n",
        "if hasattr(trainer.model, \"module\"):\n",
        "    trainer.model.module.save_pretrained(\"./trained_for_summarization_en\")\n",
        "else:\n",
        "    trainer.model.save_pretrained(\"./trained_for_summarization_en\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2efe66",
      "metadata": {
        "id": "bf2efe66"
      },
      "source": [
        "Load pre-trained model from local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2be7c430",
      "metadata": {
        "id": "2be7c430"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = (AutoModelForSeq2SeqLM\n",
        "         .from_pretrained(\"./trained_for_summarization_en\")\n",
        "         .to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca6f566",
      "metadata": {
        "id": "5ca6f566"
      },
      "source": [
        "## Generate Text (Summarize) with Fine-Tuned Model\n",
        "\n",
        "Now let's see how it generates text for summarization with fine-tuned model.<br>\n",
        "Here I generate the summarized text of test data, which has not seen in the training set.\n",
        "\n",
        "> Note : The article in XL-Sum dataset is created by removing the first sentence (headline sentence) of BBC news source, and the first sentence is then used for summary.<br>\n",
        ">  For this reason, there might exist several mismatch between article and summary in test data. (Choose appropriate samples for checking.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "4ca11263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ca11263",
        "outputId": "128fe391-7dc9-4708-fc8e-33cc93653e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Input's Text *****\n",
            "By Kate DaileyBBC News Earlier this week, Trump posted a photo of himself sitting at a desk at Mar-a-Largo, a permanent marker hovering over a notepad. \"Writing my inaugural address at the Winter White House, Mar-a-Lago, three weeks ago. Looking forward to Friday,\" he tweeted. Trump vows to end 'American carnage' Trump's angry call to arms Full text of Trump's inauguration speech It's unclear whether the president-elect actually wrote the speech himself, but the content was pure Trump: the same populist message that resonated throughout the primaries and the campaign. \"Today, we are not merely transferring power from one administration to another, or from one party to another, but we are transferring power from Washington, DC, and giving it back to you, the people,\" he said at the beginning of his remarks. For some on Twitter, it bore an eerie similarity to the Batman villain Bane's speech in The Dark Night Rises, so much so that someone posted a 10-second mash-up of the two. But such snarky reactions, warned Fox News commentator Guy Benson, underestimate how popular his rhetoric is with Trump supporters. \"People panning the speech still don't seem to understand how resonant the 'I will never ignore you' theme has been, and still is,\" he wrote, referencing Trump's many callouts to those who feel left out of American progress. Trump spoke of a country whose citizens had too long been ignored by the coastal elite: \"Their victories have not been your victories. Their triumphs have not been your triumphs. And while they celebrated in our nation's capital, there was little to celebrate for struggling families all across our land.\" He painted a picture of a broken and damaged country, dotted with rusting-out factories \"like tombstones\", city streets plagued with \"crime and the gangs, and the drugs that have stolen too many lives,\" and the wealth of the middle class \"ripped from their homes and then redistributed all across the world\". It was an unusually bleak speech for an inaugural address. One democratic strategist called it \"startlingly angry\". Conservatives were more mixed. According to MSNBC host Joe Scarborough, the speech was not intended to follow tradition: \"Donald Trump's speech was not an inaugural address. It was a primal scream aimed at Washington, DC.\" Author Hugh Hewitt called it \"authentic, determined, almost grim\". He wrote, \"I expected more joy, but it cannot be said that POTUS @realDonaldTrump said anything he hasn't said before. He has a plan and it's going to roll out fast.\" Others were sceptical of the breadth of those plans. Trump said the country was poised to \"free the earth from the miseries of disease, and to harness the energies, industries and technologies of tomorrow\", as well as \"eradicate from the face of the Earth\" radical Islamic terrorism. Writer Ben Shapiro expressed doubt about Trump's plans to both take power away from DC, and use his position as President to steer trade and create jobs. \"These cannot both be true,\" he wrote. Many also noted that it's easy to campaign as an outsider, railing about America's problems, but harder to lead, when one must find solutions. \"After three months in which Trump is president and it's still the same Washington, that speech is going to seem wildly imprudent,\" wrote Noah Rothman, assistant editor at Commentary Magazine. Commentator Mary Katherine Hahn thinks voters aren't interested in sweeping rhetoric. \"I am unabashedly ideological. The country is not. His message is populist & popular. His opponents dismiss that at their political peril.\" Pollster Frank Luntz said President Trump seemed to pivot, if not in tone then at least in substance: \"President Trump's inaugural speech was the best delivery I've ever seen from him.\" A more well-known conservative kept mum on his opinion. When the Washington Post asked George W Bush what he thought of the speech, he merely replied, \"Good to see you.\" One high-profile Twitter user was an unabashed fan. Former Ku Klux Klan leader David Duke tweeted multiple times in favour of Trump's speech.\n",
            "***** Summary Text (True Value) *****\n",
            "Donald Trump campaigned on becoming a president unlike any Washington has ever seen. With his inauguration speech, he's already set the tone.\n",
            "***** Summary Text (Generated Text) *****\n",
            "President-elect Donald Trump's speech at the Winter White House was not an inaugural address.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Predict with test data (first 5 rows)\n",
        "sample_dataloader = DataLoader(\n",
        "    tokenized_ds[\"test\"].with_format(\"torch\"),\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=5)\n",
        "for batch in sample_dataloader:\n",
        "    with torch.no_grad():\n",
        "        preds = model.generate(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            num_beams=15,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=1,\n",
        "            remove_invalid_values=True,\n",
        "            max_length=128,\n",
        "        )\n",
        "    labels = batch[\"labels\"]\n",
        "    break\n",
        "\n",
        "# Replace -100 (see above)\n",
        "labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
        "\n",
        "# Convert id tokens to text\n",
        "text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "# Show result\n",
        "print(\"***** Input's Text *****\")\n",
        "print(ds[\"test\"][\"text\"][0])\n",
        "print(\"***** Summary Text (True Value) *****\")\n",
        "print(text_labels[0])\n",
        "print(\"***** Summary Text (Generated Text) *****\")\n",
        "print(text_preds[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a4da2045",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4da2045",
        "outputId": "646f4178-0e57-407c-ddf9-bab3aceea124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Input's Text *****\n",
            "By Jon Welch and Paul MoseleyBBC News Details of health problems, family bereavements and personal issues were sent by the University of East Anglia (UEA) in Norwich to 298 students. Megan Baynes, 23, said she felt \"sick and horrified\" when she realised her details had been shared. The UEA apologised \"unreservedly\" and said an inquiry had begun. The email contained a spreadsheet listing 172 names and details extenuating circumstances in which extensions and other academic concessions were granted to 42 students. 'Felt sick' It was sent to nearly 300 undergraduates, including Ms Baynes, a former editor of student newspaper Concrete. She is currently awaiting the results of her American Literature and Creative Writing degree, and had been granted extensions for coursework because of an illness suffered by a family member. \"I felt sick at seeing my personal situation written in a spreadsheet, and then seemingly sent to everyone on my course,\" she said. \"My situation was not the worst on there but there are some on there that are so personal. There are people I know and I feel so awful for them and can't imagine how they are feeling.\" Theo Antoniou Phillips, UEA Students' Union undergraduate education officer, said: \"This is a shocking and utterly unacceptable data breach that should never have happened.\" Jo Swo, the union's welfare, community and diversity officer, said: \"Given the university is supposed to be making mental health a priority, this is a real slap in the face to students who have sought support.\" In a statement, a UEA spokeswoman said: \"An email was mistakenly sent to 298 American Studies undergraduates this morning containing details of 42 students with extenuating circumstances. \"This clearly should not have happened and the university apologises unreservedly. The university has launched an urgent enquiry and is contacting all affected students to offer support. \"Anyone needing support should call 01603 592761. The university is informing the ICO (Information Commissioner's Office).\" The ICO has been contacted for comment.\n",
            "***** Summary Text (True Value) *****\n",
            "A university has mistakenly emailed hundreds of students intimate and sensitive personal information about dozens of fellow undergraduates.\n",
            "***** Summary Text (Generated Text) *****\n",
            "A university has apologised after it mistakenly sent details of 42 students with extenuating circumstances.\n"
          ]
        }
      ],
      "source": [
        "print(\"***** Input's Text *****\")\n",
        "print(ds[\"test\"][\"text\"][2])\n",
        "print(\"***** Summary Text (True Value) *****\")\n",
        "print(text_labels[2])\n",
        "print(\"***** Summary Text (Generated Text) *****\")\n",
        "print(text_preds[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b4c854",
      "metadata": {
        "id": "e7b4c854"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97f6a925f3ac4f538d3335162c98d4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_864e0a05db1340f5b7dabeca9e048ba8",
              "IPY_MODEL_a8c78d4dc5c54ed8b1d142e59a39d461",
              "IPY_MODEL_882f45a3556e44fba9e76b6472f4905d"
            ],
            "layout": "IPY_MODEL_5effb11eac674eaca26d4f82d85e8dfc"
          }
        },
        "864e0a05db1340f5b7dabeca9e048ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d5659b56a7f450e880944fe2dd0daa0",
            "placeholder": "​",
            "style": "IPY_MODEL_a309d0de0f17402bb5621bc1ec16a4b4",
            "value": "100%"
          }
        },
        "a8c78d4dc5c54ed8b1d142e59a39d461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aef40e8d19a4903abc86c66577aaaae",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f28d9138eb004227bedc0556007f313b",
            "value": 3
          }
        },
        "882f45a3556e44fba9e76b6472f4905d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41968fbc0f424c5f93de98e7c7ec6ed7",
            "placeholder": "​",
            "style": "IPY_MODEL_006db2251be24fe7b99a7ec4932da692",
            "value": " 3/3 [00:00&lt;00:00, 52.04it/s]"
          }
        },
        "5effb11eac674eaca26d4f82d85e8dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5659b56a7f450e880944fe2dd0daa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a309d0de0f17402bb5621bc1ec16a4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aef40e8d19a4903abc86c66577aaaae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28d9138eb004227bedc0556007f313b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41968fbc0f424c5f93de98e7c7ec6ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "006db2251be24fe7b99a7ec4932da692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b8348abac7a4f0ca72a2fd9d95cfae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27f5ec664944be184f9d8f27b6b97b7",
              "IPY_MODEL_9a2e6b142cbf41bbb4e3c23851087bf3",
              "IPY_MODEL_5a237c27ae2e4a4f863e39c06a956ddd"
            ],
            "layout": "IPY_MODEL_601d10293ac3472c8f244a11ca9c9204"
          }
        },
        "e27f5ec664944be184f9d8f27b6b97b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9853745fd4154c6590e257ee175fe030",
            "placeholder": "​",
            "style": "IPY_MODEL_8f47cf72871344cfbe2eceb7a55353f6",
            "value": "Map: 100%"
          }
        },
        "9a2e6b142cbf41bbb4e3c23851087bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1aac87f32f4cd182a77e1c43a80ab2",
            "max": 11535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_732eb793dce0479ca2c98f1a39161c99",
            "value": 11535
          }
        },
        "5a237c27ae2e4a4f863e39c06a956ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ab811164014053b2d135909b931801",
            "placeholder": "​",
            "style": "IPY_MODEL_a37de51cf1504c5d8593af7ab3a578ab",
            "value": " 11520/11535 [00:38&lt;00:00, 161.76 examples/s]"
          }
        },
        "601d10293ac3472c8f244a11ca9c9204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9853745fd4154c6590e257ee175fe030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f47cf72871344cfbe2eceb7a55353f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff1aac87f32f4cd182a77e1c43a80ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "732eb793dce0479ca2c98f1a39161c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0ab811164014053b2d135909b931801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37de51cf1504c5d8593af7ab3a578ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}